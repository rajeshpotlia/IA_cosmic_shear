{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326931f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "context has already been set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_start_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#number of bin and multipoles\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyccl_env/lib/python3.11/multiprocessing/context.py:247\u001b[0m, in \u001b[0;36mDefaultContext.set_start_method\u001b[0;34m(self, method, force)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_start_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force:\n\u001b[0;32m--> 247\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext has already been set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m force:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: context has already been set"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pyccl as ccl\n",
    "import scipy.stats as stats\n",
    "import scipy.integrate as integ\n",
    "import scipy.optimize as opt\n",
    "import scipy.special as spec\n",
    "from scipy.misc import derivative\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emcee\n",
    "import os\n",
    "import time\n",
    "import timeit\n",
    "import tqdm\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "multiprocessing.set_start_method(\"fork\")\n",
    "import h5py\n",
    "\n",
    "\n",
    "#number of bin and multipoles\n",
    "bin_l = 20\n",
    "bin_euclid=13\n",
    "#muktipoles logarithmic array and difference definition\n",
    "ell = np.geomspace(2, 2000, bin_l)\n",
    "delta_ell = np.empty([bin_l])\n",
    "delta_ell[1:bin_l] = -ell[0:bin_l-1] + ell[1:bin_l]\n",
    "delta_ell[0]=ell[0]\n",
    "#redshift e bin data loading\n",
    "#euclid total\n",
    "#bin normalization and nz values\n",
    "norm_tot= np.zeros(bin_euclid)\n",
    "nz_tot= np.zeros([bin_euclid,1000])\n",
    "#redshift and noramlization values\n",
    "z_eff= np.zeros(bin_euclid)\n",
    "z_euclid = np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax.txt\", delimiter=\"\\t\", usecols=0)\n",
    "norm_tot= np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax_number_densities.txt\")\n",
    "#galaxy bias for nz total\n",
    "bias_tot= np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax_galaxy_bias.txt\",usecols=1)\n",
    "for i in range(bin_euclid):\n",
    "    nz_tot[i,:]=np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax.txt\", delimiter=\"\\t\", usecols=i+1)\n",
    "#euclid red\n",
    "#bin normalization and nz values\n",
    "norm_red= np.zeros(bin_euclid)\n",
    "nz_red= np.zeros([bin_euclid,1000])\n",
    "#redshift and noramlization values\n",
    "z_euclid = np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_red_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax.txt\", delimiter=\"\\t\", usecols=0)\n",
    "norm_red= np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_red_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax_number_densities.txt\")\n",
    "#galaxy bias for nz red\n",
    "bias_red= np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_red_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax_galaxy_bias.txt\",usecols=1)\n",
    "for i in range(bin_euclid):\n",
    "    nz_red[i,:]=np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_red_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax.txt\", delimiter=\"\\t\", usecols=i+1)\n",
    "#euclid blue\n",
    "#bin normalization and nz values\n",
    "norm_blue= np.zeros(bin_euclid)\n",
    "nz_blue= np.zeros([bin_euclid,1000])\n",
    "#redshift and noramlization values\n",
    "z_euclid = np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_blue_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax.txt\", delimiter=\"\\t\", usecols=0)\n",
    "norm_blue= np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_blue_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax_number_densities.txt\")\n",
    "#galaxy bias for nz red\n",
    "bias_blue= np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_blue_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax_galaxy_bias.txt\",usecols=1)\n",
    "for i in range(bin_euclid):\n",
    "    nz_blue[i,:]=np.loadtxt(\"/home/systembio/cosmodata/nofzs/nofz_blue_13_bins_EP_24.5_maxmag_0.2_2.5_zmin_zmax.txt\", delimiter=\"\\t\", usecols=i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba72f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sky fractions\n",
    "fsky_eu = 0.36\n",
    "#variance of the observed ellipticities\n",
    "se = 0.3\n",
    "# IAs parameters fiducial values\n",
    "eta_red = 0.\n",
    "eta_blue = 0.\n",
    "z_pivot=0.62\n",
    "A_red=2.15\n",
    "A_blue=0.03\n",
    "C_1=5e-14\n",
    "#Comsmological paramneter fiducial values\n",
    "Oc=0.27\n",
    "s8=0.83\n",
    "Omega_b=0.045\n",
    "h = 0.67\n",
    "n_s = 0.96\n",
    "w0 = -1.0\n",
    "wa = 0.0\n",
    "# Cl angular power spectra calculator\n",
    "def cl_calc(Oc,s8,Omega_b,h,n_s,w0,wa,A_red,A_blue,eta_red,eta_blue):\n",
    "    cosmo = ccl.Cosmology(Omega_c=Oc,\n",
    "                      Omega_b = Omega_b,\n",
    "                      h=h,\n",
    "                      n_s=n_s,\n",
    "                      sigma8=s8,\n",
    "                      w0 = w0,\n",
    "                      wa = wa,\n",
    "                      transfer_function='boltzmann_camb',\n",
    "                      extra_parameters = {\"camb\": {\"dark_energy_model\": \"ppf\"}})\n",
    "    D= ccl.growth_factor(cosmo, 1./(1+z_euclid))\n",
    "    rho_m = ccl.physical_constants.RHO_CRITICAL * (cosmo['Omega_c']+cosmo['Omega_b'])\n",
    "    Az_red =  A_red* C_1 * (rho_m / D)*((1+z_euclid)/(1+z_pivot))**eta_red\n",
    "    Az_blue = 5.*A_blue* C_1 * (rho_m / (D**2))*((1+z_euclid)/(1+z_pivot))**eta_blue\n",
    "    zeros_l = np.zeros(bin_l)\n",
    "    clbtracer_eu_blue = np.array([ ccl.WeakLensingTracer(cosmo, dndz=(z_euclid, nz_blue[i,:]), ia_bias=(z_euclid, Az_blue), use_A_ia=False) for i in range(bin_euclid)])\n",
    "    clbtracer_eu_red = np.array([ ccl.WeakLensingTracer(cosmo, dndz=(z_euclid, nz_red[i,:]), ia_bias=(z_euclid, Az_red), use_A_ia=False) for i in range(bin_euclid)])\n",
    "    clbtracer = np.concatenate((clbtracer_eu_blue,clbtracer_eu_red))\n",
    "\n",
    "    clij_smart = np.array([ [\n",
    "        ccl.angular_cl(cosmo, clbtracer[i], clbtracer[j], ell)\n",
    "        if j<=i else np.zeros(bin_l)\n",
    "        for j in range(bin_euclid*2) ] for i in range(bin_euclid*2) ]).T\n",
    "    clij_smart += np.triu(clij_smart, 1).transpose(0, 2, 1)\n",
    "    return clij_smart\n",
    "\n",
    "clij_smart= cl_calc(Oc,s8,Omega_b,h,n_s,w0,wa,A_red,A_blue,eta_red,eta_blue)\n",
    "# noise and variance coefficient calculation\n",
    "zeros_matrix = np.zeros([bin_l,bin_euclid,bin_euclid])\n",
    "ones_matrix = np.ones([bin_l,bin_euclid,bin_euclid])\n",
    "noise_blue= (se**2/((norm_blue*(60.*180./(np.pi))**2.)))\n",
    "noise_red= (se**2/((norm_red*(60.*180./(np.pi))**2.)))\n",
    "noise_matrix_blue= np.zeros((bin_euclid,bin_euclid), float)\n",
    "noise_matrix_red= np.zeros((bin_euclid,bin_euclid), float)\n",
    "np.fill_diagonal(noise_matrix_blue, noise_blue)\n",
    "np.fill_diagonal(noise_matrix_red, noise_red)\n",
    "noise_matrix_blue = np.array([ noise_matrix_blue for l in range(bin_l)])\n",
    "noise_matrix_red = np.array([ noise_matrix_red for l in range(bin_l)])\n",
    "\n",
    "noise = np.block([\n",
    "\n",
    "             [noise_matrix_blue[:],                 zeros_matrix[:]],\n",
    "\n",
    "             [zeros_matrix[:],                  noise_matrix_red[:]]\n",
    "\n",
    "             ])\n",
    "coeff =  np.block([\n",
    "\n",
    "             [ones_matrix[:]*np.sqrt(2./((2.*ell[:, None, None]+1.)*delta_ell[:, None, None]*fsky_eu)),                 ones_matrix[:]*np.sqrt(2./((2.*ell[:, None, None]+1.)*delta_ell[:, None, None]*fsky_eu))],\n",
    "\n",
    "             [ones_matrix[:]*np.sqrt(2./((2.*ell[:, None, None]+1.)*delta_ell[:, None, None]*fsky_eu)),                 ones_matrix[:]*np.sqrt(2./((2.*ell[:, None, None]+1.)*delta_ell[:, None, None]*fsky_eu))]\n",
    "\n",
    "             ])\n",
    "\n",
    "\n",
    "# Cl flattening and covariance matrix calculation\n",
    "clij_smart_flat = np.array([[clij_smart[l,i,j] for i in range(bin_euclid*2) for j in range(i,bin_euclid*2) ]for l in range(bin_l)])\n",
    "aij = np.array([coeff[l,:,:]*(clij_smart[l,:,:]+noise[l,:,:]) for l in range(bin_l)])\n",
    "\n",
    "inv_aij =  np.array([ np.linalg.inv(aij[l,:,:]) for l in range(bin_l) ])\n",
    "sigma = np.array([[0.5*aij[:,i,k]*aij[:,j,l] + 0.5*aij[:,i,l]*aij[:,j,k] for i in range(bin_euclid*2) for j in range(i,bin_euclid*2)] for k in range(bin_euclid*2) for l in range(k,bin_euclid*2)])\n",
    "inv_sigma = np.array([np.linalg.inv(sigma[:,:,l]) for l in range(bin_l) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37684ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    if (-0.1 < theta[0] < 0.1 and -0.1 < theta[1] < 0.1 and 1.075 < theta[2] < 3.225 and 0.01 < theta[3] < 0.05 and 0.13 < theta[4] < 0.4 and 0.4 < theta[5] < 1.25 and 0.01 < theta[6] < 0.06 and 0.3 < theta[7] < 0.9 and 0.5 < theta[8] < 1.5 and -1.5 < theta[9] < -0.5 and -0.5 < theta[10] < 0.5):\n",
    "        return 0.0\n",
    "    return -np.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c1092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnl(theta): \n",
    "    cosmo = ccl.Cosmology(Omega_c=theta[4],\n",
    "                      Omega_b = theta[6],\n",
    "                      h=theta[7],\n",
    "                      n_s=theta[8],\n",
    "                      sigma8=theta[5],\n",
    "                      w0 = theta[9],\n",
    "                      wa = theta[10],\n",
    "                      transfer_function='boltzmann_camb',\n",
    "                      extra_parameters = {\"camb\": {\"dark_energy_model\": \"ppf\"}})\n",
    "    D= ccl.growth_factor(cosmo, 1./(1+z_euclid))\n",
    "    rho_m = ccl.physical_constants.RHO_CRITICAL * (cosmo['Omega_c']+cosmo['Omega_b'])\n",
    "    Az_red =  theta[2]* C_1 * (rho_m / D)*((1+z_euclid)/(1+z_pivot))**theta[0]\n",
    "    Az_blue = 5.*theta[3]* C_1 * (rho_m / (D**2))*((1+z_euclid)/(1+z_pivot))**theta[1]\n",
    "    zeros_l = np.zeros(bin_l)\n",
    "    clbtracer_eu_blue = np.array([ ccl.WeakLensingTracer(cosmo, dndz=(z_euclid, nz_blue[i,:]), ia_bias=(z_euclid, Az_blue), use_A_ia=False) for i in range(bin_euclid)])\n",
    "    clbtracer_eu_red = np.array([ ccl.WeakLensingTracer(cosmo, dndz=(z_euclid, nz_red[i,:]), ia_bias=(z_euclid, Az_red), use_A_ia=False) for i in range(bin_euclid)])\n",
    "    clbtracer = np.concatenate((clbtracer_eu_blue,clbtracer_eu_red))\n",
    "\n",
    "    clij_smart_mod = np.array([ [\n",
    "        ccl.angular_cl(cosmo, clbtracer[i], clbtracer[j], ell)\n",
    "        if j<=i else np.zeros(bin_l)\n",
    "        for j in range(bin_euclid*2) ] for i in range(bin_euclid*2) ]).T\n",
    "    clij_smart_mod += np.triu(clij_smart_mod, 1).transpose(0, 2, 1)\n",
    "    # Cl flattening\n",
    "    clij_smart_flat_mod = np.array([[clij_smart_mod[l,i,j] for i in range(bin_euclid*2) for j in range(i,bin_euclid*2) ]for l in range(bin_l)])\n",
    "    diffij_smart_flat = clij_smart_flat_mod - clij_smart_flat\n",
    "    \n",
    "    likehood = np.array([np.linalg.multi_dot([diffij_smart_flat[l,:],inv_sigma[l,:,:],diffij_smart_flat[l,:]]) for l in range(bin_l)])\n",
    "    return -np.sum(likehood)\n",
    "    print(\"someything\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb36c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob(theta):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnl(theta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f1a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the walkers\n",
    "\n",
    "nwalkers = 22\n",
    "ndim = 11\n",
    "max_n = 10000\n",
    "np.random.seed()\n",
    "initial = [np.array([eta_red, eta_blue, A_red, A_blue, Oc , s8, Omega_b, h, n_s, w0, wa]) + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c0818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"newtry.h5\"\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "backend.reset(nwalkers, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#with Pool() as pool:\n",
    "    \n",
    "emcee.moves.StretchMove\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, backend=backend)#,pool=pool)\n",
    "\n",
    "\n",
    "# We'll track how the average autocorrelation time estimate changes\n",
    "index = 0\n",
    "autocorr = np.empty(max_n)\n",
    "\n",
    "# This will be useful to testing convergence\n",
    "old_tau = np.inf\n",
    "\n",
    "# Now we'll sample for up to max_n steps\n",
    "for sample in sampler.sample(initial, iterations=max_n, progress=True):\n",
    "    # Only check convergence every 100 steps\n",
    "    if sampler.iteration % 100:\n",
    "        continue\n",
    "\n",
    "    # Compute the autocorrelation time so far\n",
    "    # Using tol=0 means that we'll always get an estimate even\n",
    "    # if it isn't trustworthy\n",
    "    tau = sampler.get_autocorr_time(tol=0)\n",
    "    autocorr[index] = np.mean(tau)\n",
    "    index += 1\n",
    "\n",
    "    # Check convergence\n",
    "    converged = np.all(tau * 100 < sampler.iteration)\n",
    "    converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "    if converged:\n",
    "        break\n",
    "    old_tau = tau\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "        \n",
    "with Pool() as pool:\n",
    "    \n",
    "    emcee.moves.StretchMove\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, backend=backend, pool=pool)\n",
    "\n",
    "\n",
    "    # We'll track how the average autocorrelation time estimate changes\n",
    "    index = 0\n",
    "    autocorr = np.empty(max_n)\n",
    "\n",
    "    # This will be useful to testing convergence\n",
    "    old_tau = np.inf\n",
    "\n",
    "    # Now we'll sample for up to max_n steps\n",
    "    for sample in sampler.sample(initial, iterations=max_n, progress=True):\n",
    "        # Only check convergence every 100 steps\n",
    "        if sampler.iteration % 100:\n",
    "            continue\n",
    "\n",
    "        # Compute the autocorrelation time so far\n",
    "        # Using tol=0 means that we'll always get an estimate even\n",
    "        # if it isn't trustworthy\n",
    "        tau = sampler.get_autocorr_time(tol=0)\n",
    "        autocorr[index] = np.mean(tau)\n",
    "        index += 1\n",
    "\n",
    "        # Check convergence\n",
    "        converged = np.all(tau * 100 < sampler.iteration)\n",
    "        converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "        if converged:\n",
    "            break\n",
    "        old_tau = tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52523b0a-7136-49d0-a6a5-477026c1fa38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
